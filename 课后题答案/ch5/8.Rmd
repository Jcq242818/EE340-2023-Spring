Chapter 5: Exercise 8
========================================================

### a
```{r}
set.seed(1)
y = rnorm(100)
x = rnorm(100)
y = x - 2*x^2 + rnorm(100)
```

n = 100, p = 2.

$Y = X - 2 X^2 + \epsilon$.

### b
```{r 8b}
plot(x, y)
```
Quadratic plot. $X$ from about -2 to 2. $Y$ from about -8 to 2.

### c
```{r}
library(boot)
Data = data.frame(x,y)
set.seed(1)
# i.
glm.fit = glm(y~x)
cv.glm(Data, glm.fit)$delta
# ii.
glm.fit = glm(y~poly(x,2))
cv.glm(Data, glm.fit)$delta
# iii.
glm.fit = glm(y~poly(x,3))
cv.glm(Data, glm.fit)$delta
# iv.
glm.fit = glm(y~poly(x,4))
cv.glm(Data, glm.fit)$delta
```

### d
```{r}
set.seed(10)
# i.
glm.fit = glm(y~x)
cv.glm(Data, glm.fit)$delta
# ii.
glm.fit = glm(y~poly(x,2))
cv.glm(Data, glm.fit)$delta
# iii.
glm.fit = glm(y~poly(x,3))
cv.glm(Data, glm.fit)$delta
# iv.
glm.fit = glm(y~poly(x,4))
cv.glm(Data, glm.fit)$delta
```
Exact same, because LOOCV will be the same since it evaluates n folds of a
single observation.

### e
The quadratic polynomial had the lowest LOOCV test error rate. This was
expected because it matches the true form of $Y$.

### f
```{r}
summary(glm.fit)
```
p-values show statistical significance of linear and quadratic terms, which
agrees with the CV results.


