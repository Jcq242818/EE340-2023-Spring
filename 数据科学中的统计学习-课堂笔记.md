### Week 1:

1. size -> 数据量大 dimension -> 特征多
2. 监督和半监督，半监督是一半有监督一半没有监督 :一小部分数据有标签但是大部分数据还是无标签的
3. 领域泛化--有点像零样本，训练集是真实的猫狗照片，测试集是卡通动画的猫和狗 -> 模型的泛化能力更强，迁移能力更强。
4. 无监督学习中的两个重要操作：聚类与降维 ==(PCA主成分分析)==
5. 统计学习的三个元素：模型（神经网络结构，ResNet、LeNet等等），策略 (确定评判模型好坏的标准--例如 loss function) 和算法 (在模型确定的情况下进行优化，优化模型参数使得模型最优,  loss最小)
6. 正则化 -> 解决模型过拟合，引入额外项

### Week 2:

1. 非监督学习不需要训练集，而监督学习需要训练集，先训练，再预测。
2. 自监督学习：它旨在对于无标签数据 ，通过设计辅助任务（Proxy tasks） 来挖掘数据自身的表征特性作为监督信息，来提升模型的特征提取能力（PS：这里获取的监督信息不是指自监督学习所面对的原始任务标签，而是构造的辅助任务标签）。注意这里的两个关键词：无标签数据和辅助信息，这是定义自监督学习的两个关键依据。

### Week 3:

1.模型的泛化能力差是指模型过拟合。

2.KNN 需要对应的类别标签，是监督学习算法。

**3.Lecture 5 PPT 第26页的公式推导：**

![20230301173453](D:\Data\Tencent Files\3329500177\Image\SharePic\20230301173453.png)

### Week 9:

- 一说到分类默认认为这是有监督的。

